{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flight Ticket price prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeoYZts66O2hwwa6lbt0qD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1h6l814KfA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4c4efb6-587e-461a-eeb1-e729463cfca1"
      },
      "source": [
        "############ Connecting Dataset for Google driver #############\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/Dataset/Flight_Price\"\n",
        "import pandas as pd \n",
        "df_train=pd.read_excel('/content/gdrive/My Drive/Dataset/Flight_Price/Data_Train.xlsx')\n",
        "df_to_predict=pd.read_excel('/content/gdrive/My Drive/Dataset/Flight_Price/Test_set.xlsx')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Data_Train.xlsx  Sample_submission.xlsx  Test_set.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD396Wh2yD1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of rows in Training DS: \", df_train.shape)\n",
        "print(\"Number of rows in Training DS: \", df_to_predict.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWLQqDPHMP-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######### Finding Null value using pandas #########\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-WEXnYsQ-ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### Remving Null Value from Dataset ##########\n",
        "df_train.dropna(inplace=True)\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibh-yfxFRDA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55cd8a59-de81-486b-c32d-1fa730d5bf42"
      },
      "source": [
        "#Select Duplicate Value\n",
        "df_train.duplicated()\n",
        "#Select Duplicate rows expect first occurrence based on all columns\n",
        "duplicateRowsDF = df_train[df_train.duplicated()]\n",
        "print(\"Total Duplicate rows expect first occurrence are :\")\n",
        "duplicateRowsDF.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Duplicate rows expect first occurrence are :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3eoOD9PL7-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove duplicate rows in training dataset\n",
        "#keep= first allows us to keep the first\n",
        "df_train.drop_duplicates(keep='first', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thVXOeTHNtty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########df[\"isWeekend\"] = ((pd.to_datetime(df[\"Date_of_Journey\"], format='%d/%m/%Y').dt.dayofweek).astype(int)\n",
        "df_train[\"isWeekend\"] = ((pd.to_datetime(df_train[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.dayofweek) // 5 == 1).astype(int)\n",
        "df_train[\"Day_of_Week\"] = pd.to_datetime(df_train[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.day_name()\n",
        "df_train[\"Day_Of_Journey\"] = pd.to_datetime(df_train[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.day\n",
        "df_train[\"Month_of_Journey\"] = pd.to_datetime(df_train[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.month"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGnhnTLqRCMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######Selecting a perticular column as an list\n",
        "duration = list(df_train[\"Duration\"])\n",
        "#######Selection a perticular column as object\n",
        "duration1 = df_train['Duration'].head()\n",
        "print(duration)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdg60QA2J8xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(duration)) :\n",
        "    if len(duration[i].split()) != 2:\n",
        "        if 'h' in duration[i] :\n",
        "            duration[i] = duration[i].strip() + ' 0m'\n",
        "        elif 'm' in duration[i] :\n",
        "            duration[i] = '0h {}'.format(duration[i].strip())\n",
        "\n",
        "dur_hours = []\n",
        "dur_minutes = []  \n",
        "dur_seconds = []\n",
        "for i in range(len(duration)) :\n",
        "    dur_minutes.append(int(duration[i].split()[0][:-1])*60 + int(duration[i].split()[1][:-1]))\n",
        "    dur_seconds.append(int(duration[i].split()[0][:-1])*60*60 + int(duration[i].split()[1][:-1])*60)\n",
        "df_train[\"Duration_minutes\"] = dur_minutes\n",
        "df_train.drop([\"Duration\"], axis=1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eg1TRG-fCQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X = df_train.drop(['Price'], axis=1)\n",
        "y = np.log1p(df_train[\"Price\"])\n",
        "X_to_predict = df_to_predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiW0qk55MyHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"To find perticular data type field\n",
        "X.select_dtypes(include='float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F05QHRLZZNn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Now we are going to implement same cleaning operation\n",
        "to the Test Data set \"\"\"\n",
        "df_to_predict.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzPCOTteDSRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP6u6Nh_CeuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "54935d27-71c1-4c6c-c028-1178a7aa6c36"
      },
      "source": [
        "# Find duplicated valu in test dataset\n",
        "#Select Duplicate Value\n",
        "df_to_predict.duplicated()\n",
        "#Select Duplicate rows expect first occurrence based on all columns\n",
        "duplicateRowsDF_toTest = df_to_predict[df_to_predict.duplicated()]\n",
        "print(\"Total Duplicate rows expect first occurrence are :\")\n",
        "duplicateRowsDF_toTest.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Duplicate rows expect first occurrence are :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJE3wF61D2CO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_to_predict.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgbRNTmqFRX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######## Data Cleaning ###########\n",
        "# df_to_predict.head()\n",
        "# print(\"Train Set:\\n\", df_to_predict[\"Additional_Info\"].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBywIQCdJPpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########df[\"isWeekend\"] = ((pd.to_datetime(df[\"Date_of_Journey\"], format='%d/%m/%Y').dt.dayofweek).astype(int)\n",
        "df_to_predict[\"isWeekend\"] = ((pd.to_datetime(df_to_predict[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.dayofweek) // 5 == 1).astype(int)\n",
        "df_to_predict[\"Day_of_Week\"] = pd.to_datetime(df_to_predict[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.day_name()\n",
        "df_to_predict[\"Day_Of_Journey\"] = pd.to_datetime(df_to_predict[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.day\n",
        "df_to_predict[\"Month_of_Journey\"] = pd.to_datetime(df_to_predict[\"Date_of_Journey\"], format = '%d/%m/%Y').dt.month"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1717HQcJ97F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######Selecting a perticular column as an list\n",
        "duration_to_predict = list(df_to_predict[\"Duration\"])\n",
        "print(duration_to_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sk0i_rIKy8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(duration_to_predict)) :\n",
        "    if len(duration_to_predict[i].split()) != 2:\n",
        "        if 'h' in duration_to_predict[i] :\n",
        "            duration_to_predict[i] = duration_to_predict[i].strip() + ' 0m'\n",
        "        elif 'm' in duration_to_predict[i] :\n",
        "            duration_to_predict[i] = '0h {}'.format(duration_to_predict[i].strip())\n",
        "\n",
        "dur_hours = []\n",
        "dur_minutes = []  \n",
        "dur_seconds = []\n",
        "for i in range(len(duration_to_predict)) :\n",
        "    dur_minutes.append(int(duration_to_predict[i].split()[0][:-1])*60 + int(duration_to_predict[i].split()[1][:-1]))\n",
        "    dur_seconds.append(int(duration_to_predict[i].split()[0][:-1])*60*60 + int(duration_to_predict[i].split()[1][:-1])*60)\n",
        "df_to_predict[\"Duration_minutes\"] = dur_minutes\n",
        "df_to_predict.drop([\"Duration\"], axis=1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RRZTg8bQTU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_to_predict = df_to_predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhrMXqqMO3S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separate Categorical and Numerical Column in Dataframe (df_test)\n",
        "X_categorical = X.select_dtypes(exclude=['int', 'float'])\n",
        "X_numerical = X.select_dtypes(include=['int', 'float'])\n",
        "#Separate Categorical and Numerical Column in Dataframe (Predict set)\n",
        "X_to_predict_categorical = X_to_predict.select_dtypes(exclude=['int', 'float'])\n",
        "X_to_predict_numerical = X_to_predict.select_dtypes(include=['int', 'float'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHvNxizmPcya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label Encode and Hot encode categforical column\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X_categorical = X_categorical.apply(le.fit_transform)\n",
        "X_to_predict_categorical = X_to_predict_categorical.apply(le.fit_transform);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb0Kqroilgeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In the case of numerical features, we can perform different types of scaling like MinMax, StandardScaler or BoxCox tranformation.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwNiQO3fL7Cv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}